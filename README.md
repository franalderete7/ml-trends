# The Hottest Trends in Machine Learning
This project is a part of DataCamp projects section.

#### -- Project Status: [Completed]

## Project Intro/Objective
The purpose of this project is to analyse papers from the NIPS conference (Neural Information Processing Systems) with natural language processing methods in order to discover what are the trendiest topics in machine learning. By analysing these trendiest topics, we can infer what are the most innovative techniques and algorithms used by each year. We'll explore papers from 1987 to 2017 (30 years). 

### Methods Used
* Inferential Statistics
* Data Visualization
* Predictive Modeling
* Data Cleaning
* Data Filtering
* Natural Language Processing

### Technologies
* Python
* Numpy, Pandas, Matplotlib, Scikit-learn

## Project Description
The NIPS conference (Neural Information Processing Systems) is one of the most prestigious yearly events in the machine learning community. At each NIPS conference, a large number of research papers are published. Over 50,000 PDF files were automatically downloaded and processed to obtain a dataset on various machine learning techniques. These NIPS papers are stored in datasets/papers.csv. The CSV file contains information on the different NIPS papers that were published from 1987 until 2017 (30 years!). These papers discuss a wide variety of topics in machine learning, from neural networks to optimization methods and many more. The logo of NIPS (Neural Information Processing Systems)
First, we will explore the CSV file to determine what type of data we can use for the analysis and how it is structured. A research paper typically consists of a title, an abstract and the main text. Other data such as figures and tables were not extracted from the PDF files. Each paper discusses a novel technique or improvement. In this analysis, we will focus on analyzing these papers with natural language processing methods.

## Needs of this project

- frontend developers
- data exploration/descriptive statistics
- data processing/cleaning
- statistical modeling
- writeup/reporting


## Getting Started

1. Clone this repo (for help see this [tutorial](https://help.github.com/articles/cloning-a-repository/)).
2. Raw Data is being kept [here](Repo folder containing raw data) within this repo.   
3. Data processing/transformation scripts are being kept [here](Repo folder containing data processing scripts/notebooks)
4. Follow setup [instructions](Link to file)
